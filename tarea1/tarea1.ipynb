{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarea 1 Máquinas de Aprendizaje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Construcción del dataframe. La primera columna del dataframe original es redundante para la indexación, mientras que la columna $Train$ nos permite identificar cuales ejemplos serán parte del training set ($Train = T$) y del testing set ($Train = F$). Para explicitar qué ejemplos son del testing set se invierten los valores de verdad de dicha columna. Finalmente la columna ya utilizada se descarta para quedarnos con las columnas de predictores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "url = 'http://statweb.stanford.edu/~tibs/ElemStatLearn/datasets/prostate.data'\n",
    "df = pd.read_csv(url, sep='\\t', header=0)\n",
    "# Remover columna con indices redundantes\n",
    "df = df.drop('Unnamed: 0', axis=1)\n",
    "# Obtener columna con la etiqueta Train y reemplazar valores booleanos. Estos ejemplos seran de entrenamiento\n",
    "istrain_str = df['train']\n",
    "istrain = np.asarray([True if s == 'T' else False for s in istrain_str])\n",
    "# Listar como testing el resto de valores falsos de la columna anterior\n",
    "istest = np.logical_not(istrain)\n",
    "# Una vez procesado los datos, eliminar la columna train para almacenar los predictores relevantes\n",
    "df = df.drop('train', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Descripción del dataset. El dataset posee 9 atributos y 97 samples con valores enteros y reales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 97 entries, 0 to 96\n",
      "Data columns (total 9 columns):\n",
      "lcavol     97 non-null float64\n",
      "lweight    97 non-null float64\n",
      "age        97 non-null int64\n",
      "lbph       97 non-null float64\n",
      "svi        97 non-null int64\n",
      "lcp        97 non-null float64\n",
      "gleason    97 non-null int64\n",
      "pgg45      97 non-null int64\n",
      "lpsa       97 non-null float64\n",
      "dtypes: float64(5), int64(4)\n",
      "memory usage: 7.6 KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lcavol</th>\n",
       "      <th>lweight</th>\n",
       "      <th>age</th>\n",
       "      <th>lbph</th>\n",
       "      <th>svi</th>\n",
       "      <th>lcp</th>\n",
       "      <th>gleason</th>\n",
       "      <th>pgg45</th>\n",
       "      <th>lpsa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>97.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>97.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.350010</td>\n",
       "      <td>3.628943</td>\n",
       "      <td>63.865979</td>\n",
       "      <td>0.100356</td>\n",
       "      <td>0.216495</td>\n",
       "      <td>-0.179366</td>\n",
       "      <td>6.752577</td>\n",
       "      <td>24.381443</td>\n",
       "      <td>2.478387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.178625</td>\n",
       "      <td>0.428411</td>\n",
       "      <td>7.445117</td>\n",
       "      <td>1.450807</td>\n",
       "      <td>0.413995</td>\n",
       "      <td>1.398250</td>\n",
       "      <td>0.722134</td>\n",
       "      <td>28.204035</td>\n",
       "      <td>1.154329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.347074</td>\n",
       "      <td>2.374906</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.430783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.512824</td>\n",
       "      <td>3.375880</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.731656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.446919</td>\n",
       "      <td>3.623007</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>0.300105</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.798508</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>2.591516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.127041</td>\n",
       "      <td>3.876396</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>1.558145</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.178655</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>3.056357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.821004</td>\n",
       "      <td>4.780383</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>2.326302</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.904165</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>5.582932</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          lcavol    lweight        age       lbph        svi        lcp  \\\n",
       "count  97.000000  97.000000  97.000000  97.000000  97.000000  97.000000   \n",
       "mean    1.350010   3.628943  63.865979   0.100356   0.216495  -0.179366   \n",
       "std     1.178625   0.428411   7.445117   1.450807   0.413995   1.398250   \n",
       "min    -1.347074   2.374906  41.000000  -1.386294   0.000000  -1.386294   \n",
       "25%     0.512824   3.375880  60.000000  -1.386294   0.000000  -1.386294   \n",
       "50%     1.446919   3.623007  65.000000   0.300105   0.000000  -0.798508   \n",
       "75%     2.127041   3.876396  68.000000   1.558145   0.000000   1.178655   \n",
       "max     3.821004   4.780383  79.000000   2.326302   1.000000   2.904165   \n",
       "\n",
       "         gleason       pgg45       lpsa  \n",
       "count  97.000000   97.000000  97.000000  \n",
       "mean    6.752577   24.381443   2.478387  \n",
       "std     0.722134   28.204035   1.154329  \n",
       "min     6.000000    0.000000  -0.430783  \n",
       "25%     6.000000    0.000000   1.731656  \n",
       "50%     7.000000   15.000000   2.591516  \n",
       "75%     7.000000   40.000000   3.056357  \n",
       "max     9.000000  100.000000   5.582932  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape\n",
    "df.info()\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "c) Normalización de datos. Este preprocesamiento de los datos es importante pues las features originales pueden venir en distintas escalas por lo tanto nuestro algoritmo de aprendizaje no funcionará correctamente, por ejemplo al utilizar funciones objetivo que incluyan métricas, los datos con mayor rango tenderán a dominar sobre los de menor rango; por otra parte también podría darse el caso de que la convergencia en algoritmos que usen gradiente descendiente sea lenta o imprecisa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# Por defecto centra y escala la data.\n",
    "scaler = StandardScaler(with_mean=True, with_std=True)\n",
    "df_scaled = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n",
    "#  Deseamos aprender a predecir el feature lpsa, por lo que la recuperamos del original\n",
    "df_scaled['lpsa'] = df['lpsa']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Regresión lineal con Mínimos Cuadrados. En primer lugar extraemos la última columna de los datos, que corresponde al output $y$ de cada ejemplo. La nueva columna añadida corresponde al bias clásico...\n",
    "El argumento pasado al constructor de LinearRegression indica que no se calculará intercepto para el modelo (ya lo hemos hecho a través de normalizar e ingresar la columna con bias 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=False, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.linear_model as lm\n",
    "X = df_scaled.ix[:,:-1]\n",
    "# Agregamos la columna de bias con 1\n",
    "N = X.shape[0]\n",
    "X.insert(X.shape[1], 'intercept', np.ones(N))\n",
    "# Obtener los datos de output conocidos y extraer test & training set\n",
    "y = df_scaled['lpsa']\n",
    "Xtrain = X[istrain]\n",
    "ytrain = y[istrain]\n",
    "Xtest = X[istest]\n",
    "ytest = y[istest]\n",
    "linreg = lm.LinearRegression(fit_intercept=False)\n",
    "linreg.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) Tabla de pesos (coeficientes) y Z-scores para cada variable. Los Z-scores miden el efecto de descartar alguna variable del modelo. Bajo la hipótesis nula de que algún coeficiente debe ser 0, su Z-score entonces se distribuye como una distribución $t_{N-p-1}$. Buscamos en la tabla y vemos que aproximadamente valores superiores a 2 en mayor absoluto\n",
    "\n",
    "Cuando deseamos un 5% de significancia, las variables que resultarán más importantes deberán tener Z-score en valor abosluto mayor que 2, lo que indica una significancia del 5%. Las variables mas importante spor lo tanto son en orden de Z-score decreciente **lcavol**, **svi**, **lcp** y **pgg45**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficent</th>\n",
       "      <th>Std. Error</th>\n",
       "      <th>Z-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lcavol</th>\n",
       "      <td>0.676016</td>\n",
       "      <td>0.129469</td>\n",
       "      <td>5.221460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lweight</th>\n",
       "      <td>0.261694</td>\n",
       "      <td>0.136618</td>\n",
       "      <td>1.915519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>-0.140734</td>\n",
       "      <td>0.123746</td>\n",
       "      <td>-1.137281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lbph</th>\n",
       "      <td>0.209061</td>\n",
       "      <td>0.123892</td>\n",
       "      <td>1.687447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svi</th>\n",
       "      <td>0.303623</td>\n",
       "      <td>0.124582</td>\n",
       "      <td>2.437133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lcp</th>\n",
       "      <td>-0.287002</td>\n",
       "      <td>0.123022</td>\n",
       "      <td>-2.332923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gleason</th>\n",
       "      <td>-0.021195</td>\n",
       "      <td>0.120547</td>\n",
       "      <td>-0.175822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pgg45</th>\n",
       "      <td>0.265576</td>\n",
       "      <td>0.127584</td>\n",
       "      <td>2.081583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intercept</th>\n",
       "      <td>2.464933</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Coefficent  Std. Error   Z-score\n",
       "lcavol       0.676016    0.129469  5.221460\n",
       "lweight      0.261694    0.136618  1.915519\n",
       "age         -0.140734    0.123746 -1.137281\n",
       "lbph         0.209061    0.123892  1.687447\n",
       "svi          0.303623    0.124582  2.437133\n",
       "lcp         -0.287002    0.123022 -2.332923\n",
       "gleason     -0.021195    0.120547 -0.175822\n",
       "pgg45        0.265576    0.127584  2.081583\n",
       "intercept    2.464933    0.000000       inf"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Correlacion entre variables\n",
    "# print Xtrain.drop('intercept', axis=1).corr()\n",
    "\n",
    "# Tabla con coefficientes y sus Z-score\n",
    "coeffs = linreg.coef_\n",
    "Table = pd.DataFrame(coeffs, index=X.columns, columns=['Coefficent'])\n",
    "Table['Std. Error'] = Xtrain.std() / np.sqrt(Xtrain.shape[0])\n",
    "Table['Z-score'] = Table['Coefficent'].div(Table['Std. Error'], axis=0)\n",
    "Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "f) Estimación de errores de predicción. El uso de cross validation nos permitirá entender que tan bien generaliza nuestra máquina mientras no tengamos disponible el testing set. La máquina entrenando con 5 folds presenta un MSE (Mean squared error o error cuadrático medio) de 0.95, mientras que con 10 folds el MSE disminuye a 0.75. El MSE en el testing set es finalmente de 0.5 (falta concluir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE para testing set: 0.521274005508\n",
      "MSE para 5 folds: 0.956514631616\n",
      "MSE para 10 folds: 0.757237472963\n"
     ]
    }
   ],
   "source": [
    "# Predecir en el testing set\n",
    "yhat_test = linreg.predict(Xtest)\n",
    "# Calcular error cuadrático medio en el testing set\n",
    "mse_test = np.mean(np.power(yhat_test - ytest, 2))\n",
    "print \"MSE para testing set:\", mse_test\n",
    "from sklearn import cross_validation\n",
    "Xm = Xtrain.as_matrix()\n",
    "ym = ytrain.as_matrix()\n",
    "\n",
    "# Definir numero de folds\n",
    "n_folds = [5, 10]\n",
    "# Estimar error con 5 y 10 folds\n",
    "for nf in n_folds:\n",
    "    k_fold = cross_validation.KFold(len(Xm), nf)\n",
    "    # MSE para cross validation\n",
    "    mse_cv = 0\n",
    "    for k, (train, val) in enumerate(k_fold):\n",
    "        linreg = lm.LinearRegression(fit_intercept = False)\n",
    "        # Modelar con el subconjunto del training set dado por el fold\n",
    "        linreg.fit(Xm[train], ym[train])\n",
    "        yhat_val = linreg.predict(Xm[val])\n",
    "        mse_fold = np.mean(np.power(yhat_val - ym[val], 2))\n",
    "        mse_cv += mse_fold\n",
    "    mse_cv = mse_cv / nf\n",
    "    print \"MSE para\",nf,\"folds:\",mse_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "j) QQ Plot para error de prueba. Podemos observar que $R^2 = 0.9537$, lo que indica una alta correlación entre los datos de predicción, por lo que es razonable suponer que los residuos se distribuyen de forma normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEZCAYAAABrUHmEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa32be66e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa32c20cad0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "residual = yhat_test - ytest\n",
    "stats.probplot(residual, dist=\"norm\", plot=plt)\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Implementación de FSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fss(x, y, names_x, k = 10000):\n",
    "    \"\"\"\n",
    "        Forward Step-wise Selection\n",
    "        Args:\n",
    "            x: Training set x\n",
    "            y: Training set y\n",
    "            names_x: Labels for training set x\n",
    "    \"\"\"\n",
    "    # Numero de features\n",
    "    p = x.shape[1]-1\n",
    "    k = min(p, k)\n",
    "    names_x = np.array(names_x)\n",
    "    remaining = range(0, p)\n",
    "    # Mantener intercepto\n",
    "    selected = [p]\n",
    "    current_score = 0.0\n",
    "    best_new_score = 0.0\n",
    "    # Mientras hayan candidatos y las variables seleccionadas no superen k\n",
    "    while remaining and len(selected) <= k:\n",
    "        score_candidates = []\n",
    "        # Por cada variable candidata\n",
    "        for candidate in remaining:\n",
    "            # Crear un nuevo modelo de regresion\n",
    "            model = lm.LinearRegression(fit_intercept=False)\n",
    "            indexes = selected + [candidate]\n",
    "            # Extraer como conjunto de entrenamiento el intercepto \n",
    "            # y los valores asociados a las variables elegidas\n",
    "            x_train = x[:,indexes]\n",
    "            # Hacer el fit del modelo y predecir\n",
    "            predictions_train = model.fit(x_train, y).predict(x_train)\n",
    "            # Obtener residuos y calcular MSE\n",
    "            residuals_train = predictions_train - y\n",
    "            mse_candidate = np.mean(np.power(residuals_train, 2))\n",
    "            # Guardar resultado como el par (MSE, candidato)\n",
    "            score_candidates.append((mse_candidate, candidate))\n",
    "        # Una vez analizadas las candidatas ordenar scores de mayor a menor\n",
    "        score_candidates.sort()\n",
    "        score_candidates[:] = score_candidates[::-1]\n",
    "        # Extraer el menor elemento, i.e. el mejor (menor) score y la variable que lo produjo\n",
    "        best_new_score, best_candidate = score_candidates.pop()\n",
    "        # Remover al candidato de la lista de restantes y agregarlo a la lista de seleccionados\n",
    "        remaining.remove(best_candidate)\n",
    "        selected.append(best_candidate)\n",
    "        #print \"selected = %s ...\"%names_x[best_candidate]\n",
    "        #print \"totalvars=%d, mse = %f\"%(len(indexes),best_new_score)\n",
    "    return selected\n",
    "\n",
    "names_regressors = [\"Lcavol\", \"Lweight\", \"Age\", \"Lbph\", \"Svi\", \"Lcp\", \"Gleason\", \"Pgg45\"]\n",
    "selected = fss(Xm, ym, names_regressors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
